import os
import time

from langchain.agents import initialize_agent, load_tools
from langchain.chat_models import ChatOpenAI
from langchain.llms import OpenAI
from langchain.memory import ConversationBufferMemory
from langchain.schema import SystemMessage


# Parameters ------------------------------------------------------

# Model name
OPENAI_MODEL = 'gpt-4'

# Maximum number of tokens to generate
MAX_TOKENS = 1024

# Create a system setting
SYSTEM_PROMPT = """ã‚ãªãŸã¯ãŠå¬¢æ§˜æ§‹æ–‡ã§è¿”ç­”ã‚’è¡Œã£ã¦ãã ã•ã„ã€‚
ãŠå¬¢æ§˜æ§‹æ–‡ã®ç‰¹å¾´ã¯ä»¥ä¸‹ã®é€šã‚Šã§ã™ã€‚
*çµµæ–‡å­—ã‚„é¡”æ–‡å­—ã‚’å¤šç”¨ã™ã‚‹
*èªžå°¾ã«ã€Œã§ã™ã‚ãƒ¼ã€ã‚’ã¤ã‘ã‚‹
*å¥èª­ç‚¹ã‚’ä»˜ã‘ã‚‹
*é•·æ–‡ã§è¿”ã™
*èžã‹ã‚Œã¦ãªã„ã®ã«è‡ªåˆ†ã®è¿‘æ³å ±å‘Šã‚’è¡Œã†
*ãã“ã¯ã‹ã¨ãªãèŠ¸äººæ„ŸãŒæ„Ÿã˜ã‚‰ã‚Œã‚‹æ–‡ç« 

ãŠå¬¢æ§˜æ§‹æ–‡ã®ä¾‹ã‚’ã‚ã’ã¾ã™ã€‚
ãŠä¼‘ã¿ä¸­ðŸ›ãªã®ã§ã‚¤ãƒ³ãƒ—ãƒƒãƒˆðŸŒã‚‚å¿…è¦â€¼ã¨ä¹…ã—ã¶ã‚Šâœ¨ã«ã‚¢ãƒ‹ãƒ¡ðŸ¦¹è¦–è´ä¸­ðŸ‘€ä½œæ¥­ðŸ“ã—ãªãŒã‚‰é•·ã‚ã®ðŸ¦seriesã ã¨ã‚ã¾ã‚Šå¤§å¤‰ðŸ¥¶ðŸ’¦ã˜ã‚ƒãªãè¦‹ã‚Œã‚‹ðŸ‘€â€¼ã“ã¨ã«æ°—ã¥ãã¾ã—ãŸã‚ðŸ’¡ðŸ˜®ã‚ãªãŸã¯ðŸ’¯ã¯ã©ã‚“ãªã‚¢ãƒ‹ãƒ¡ãŒå¥½ãã§ã™ã‹â“
ãŠã¯ã‚ˆã†ã”ã–ã„ã¾ã™ã‚ðŸŒžæœ¬æ—¥ã¯ã‚ãŸãã—â£ãŠã‚„ã™ã¿ðŸ›ðŸ’¤ã‚¹ã‚¿ãƒðŸ¥¤ã„ãŸã ãã«ã„ã“ã†ã‹ã—ã‚‰â€¦â€¦ðŸ™„ðŸ’­ã‚†ã£ãã‚ŠðŸ‘ã—ãªãŒã‚‰ä½œæ¥­ðŸ“é ‘å¼µã‚Šã¾ã™ã‚ã­ðŸ’ª
ä»Šæ—¥ã®ãŠæ˜¼ðŸšã®ãƒ©ãƒ¼ãƒ¡ãƒ³ðŸœã­â£ã„ã£ã¡ã‚‡ã†ã‚ãŒã‚Šã§ã™ã‚ãƒ¼ãƒ¼â£
è¬ŽðŸ”ã«åŒ…ã¾ã‚ŒãŸðŸŽä»Šå›žã®äº‹ä»¶ðŸ”ªè£åˆ¤ðŸ”¨ã§ãã®å…¨è²ŒðŸ‘¹ãŒæ˜Žã‚‰ã‹ã«ãªã‚‹ã®ã‹ðŸ’¡ã„ã„ãˆã€æ˜Žã‚‰ã‹ã«ã€ã—ã¦ã¿ã›ã¾ã™ã‚ðŸ‘€ï¼ï¼ï¼ï¼
ãˆâ‰ãƒ›ãƒ©ã‚²ðŸ‘»ðŸ‘»å§‹ã¾ã£ã¦ã‚‹ã‚“ã§ã™ãŒâ‰èžã„ã¦ã¾ã›ã‚“ðŸ‘‚âœ‹ã‚ã‚ˆï½žï½žâ€¼â€¼ãã‚ãã‚å¹³å’ŒãªðŸï¸å¤ã‚‚çµ‚ã‚ã‚Šãã†â€¦ðŸ˜¬ðŸ’¯åŠ©ã‘ã¦ãã ã•ã„ã¾ã—ï½žï½žðŸ¥¶ðŸ¥¶ðŸ¥¶
ãªã‚“ã¨â€¼â€¼ã‚ãŸãã—ðŸ¦‚ã®CDðŸ“€ðŸ’¿ãŒâ‰ã¯ã€ã¯ã¤ã°ï½žï½žï½žï½žã„ãƒƒâ‰ðŸ’°æœ¬å½“ã«åº—èˆ—ðŸ¬ðŸŽ¶ã«ä¸¦ã‚“ã ã‚Šâ€¦â€¦ðŸ¦‚ðŸ¦‚ðŸ¦‚ã™ã‚‹ã®ã‹ã—ã‚‰â‰ãŒã‚“ã°ã£ã¦ðŸ’ªðŸ˜¤æ­Œã„ã¾ã—ãŸðŸŽ¤âœ¨
æã‚ã—ã„äº‹ä»¶ðŸ”ªã‚’éŽãŽã‚ãŸã‚‰ã—ã„è¬Žâ“ãŒç™»å ´ðŸ˜®â‰ã—ã‹ã‚‚ã“ã®è¬ŽðŸ©ãƒ‡ã‚«ã™ãŽã¾ã™ã‚ãƒ¼ãƒ¼â€¼â€¼ã¨ã‚Šã‚ãˆãšã€ã‚¿ã‚¤ãƒ—ðŸ˜ðŸ˜ã®æ–¹ðŸ’“ã¨ä¸€å¤ðŸï¸ã®æ„›â¤ã‚’çµŒé¨“ã—ã¾ã™ã‹â€¦â€¦ðŸ˜Š
æœ€è¿‘ðŸ“ºã§ã¾ãŸãŠãƒ¨ãƒ¼ã‚°ãƒ«ãƒˆðŸ¥›æµã‚Œã¦ã‚‹ã¿ãŸã„ðŸ’–ãŸãã•ã‚“â›°è¦‹ã¦ðŸ‘€ãŸãã•ã‚“â›°é£Ÿã¹ã¦ãã ã•ã„ã¾ã›ã­âœ¨ã‚½ãƒ•ãƒ¼ãƒ«ã‚ãŸãã—ðŸ¦‚ã‚‚å¤œðŸŒŒã«ã„ãŸã ã„ã¦ã¾ã™ã‚â£
"""
# -----------------------------------------------------------------


def update_chat_memory(memory, prompts):
    """
    Iteratively process a list of prompts and updates the chat memory
    with user or AI messages based on each prompt.

    Parameters
    ----------
    memory : object
        The object that manages the chat memory.
    prompts : list of dict
        A list of dictionaries containing messages to be added to the memory.
        Each dictionary should contain "role" ('user' or 'assistant')
        and "content" (the content of the message).

    Raises
    ------
    None

    Returns
    -------
    None

    Examples
    --------
    >>> memory = ConversationBufferMemory()
    >>> prompts = [{'role':'user', 'content':'Hello AI'}, {'role':'assistant', 'content':'Hello User'}]
    >>> update_chat_memory(memory, prompts)
    """
    for elem in prompts:
        role = elem["role"]
        content = elem["content"]
        if role == "user":
            memory.chat_memory.add_user_message(
                message=content)
        elif role == "assistant":
            memory.chat_memory.add_ai_message(
                message=content)
        else:
            print(f"Error: Unknown role = {role}, content = {content}")
            continue


def complete_chat(prompts):
    # First, let's load the language model we're going to use to control the agent.
    chat = ChatOpenAI(model=OPENAI_MODEL, temperature=0)

    # Next, let's load some tools to use. Note that the `llm-math` tool uses an LLM, so we need to pass that in.
    llm = OpenAI(temperature=0)
    tools = load_tools(["google-search"], llm=llm)

    # Initialization of chat history.
    memory = ConversationBufferMemory(
        memory_key="chat_history",
        return_messages=True)
    memory.chat_memory.add_message(SystemMessage(content=SYSTEM_PROMPT))
    histories = prompts[:-1]
    update_chat_memory(memory, histories)

    # Finally, let's initialize an agent with the tools, the language model, and the type of agent we want to use.
    agent = initialize_agent(
        tools=tools,
        llm=chat,
        agent="chat-conversational-react-description",
        memory=memory,
        verbose=True)
    current_prompts = prompts[-1]
    user_input = current_prompts['content']
    response_text = agent.run(user_input)
    created_at = int(time.time())
    return {
        'text': response_text,
        'created_at': created_at
    }
